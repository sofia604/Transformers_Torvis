{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn import metrics \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos=pd.read_csv(\"../Data/SCADA_data_WT2339.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'date_time': datos['date_time'] ,'TempEjeLento_1': datos['TempEjeLento_1'], 'TempAmbMean': datos['TempAmbMean'], 'TempRodamMultipMean': datos['TempRodamMultipMean'], 'TempCojLAMean': datos['TempCojLAMean'],'TempCojLOAMean': datos['TempCojLOAMean'], 'TempGenMean': datos['TempGenMean'], 'PotMean': datos['PotMean'], 'VelRotorMean': datos['VelRotorMean']})\n",
    "cols = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PotMean\n",
    "df['PotMean'][df['PotMean']< 0] = None\n",
    "df['PotMean'][df['PotMean']> 2000] = None\n",
    "#TempAmbMean\n",
    "df['TempAmbMean'][df['TempAmbMean']< -5] = None\n",
    "df['TempAmbMean'][df['TempAmbMean']> 40] = None\n",
    "#TempCojLAMean\n",
    "df['TempCojLAMean'][df['TempCojLAMean']< 0] = None\n",
    "df['TempCojLAMean'][df['TempCojLAMean']> 120] = None\n",
    "#TempCojLOAMean\n",
    "df['TempCojLOAMean'][df['TempCojLOAMean']< 0] = None\n",
    "df['TempCojLOAMean'][df['TempCojLOAMean']> 120] = None\n",
    "#TempEjeLento_1\n",
    "df['TempEjeLento_1'][df['TempEjeLento_1']< 0] = None\n",
    "df['TempEjeLento_1'][df['TempEjeLento_1']> 120] = None\n",
    "#TempGenMean\n",
    "df['TempGenMean'][df['TempGenMean']< 0] = None\n",
    "df['TempGenMean'][df['TempGenMean']> 175] = None\n",
    "#TempRodamMultipMean\n",
    "df['TempRodamMultipMean'][df['TempRodamMultipMean']< 0] = None\n",
    "df['TempRodamMultipMean'][df['TempRodamMultipMean']> 120] = None\n",
    "#VelRotorMean\n",
    "df['VelRotorMean'][df['VelRotorMean']< 0] = None\n",
    "df['VelRotorMean'][df['VelRotorMean']> 50] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TempAmbMean']=df['TempAmbMean'].interpolate(method='pchip', order=3, limit_area='inside')\n",
    "df['TempAmbMean']=df['TempAmbMean'].fillna(method='backfill')\n",
    "df['TempAmbMean']=df['TempAmbMean'].fillna(method='ffill')\n",
    "\n",
    "df['TempEjeLento_1']=df['TempEjeLento_1'].interpolate(method='pchip', order=3)\n",
    "df['TempEjeLento_1']=df['TempEjeLento_1'].fillna(method='backfill')\n",
    "\n",
    "df['TempRodamMultipMean']=df['TempRodamMultipMean'].interpolate(method='pchip', order=3)\n",
    "df['TempRodamMultipMean']=df['TempRodamMultipMean'].fillna(method='backfill')\n",
    "\n",
    "df['TempCojLAMean']=df['TempCojLAMean'].interpolate(method='pchip', order=3)\n",
    "df['TempCojLAMean']=df['TempCojLAMean'].fillna(method='backfill')\n",
    "\n",
    "df['TempCojLOAMean']=df['TempCojLOAMean'].interpolate(method='pchip', order=3)\n",
    "df['TempCojLOAMean']=df['TempCojLOAMean'].fillna(method='backfill')\n",
    "\n",
    "df['TempGenMean']=df['TempGenMean'].interpolate(method='pchip', order=3)\n",
    "df['TempGenMean']=df['TempGenMean'].fillna(method='backfill')\n",
    "\n",
    "df['PotMean']=df['PotMean'].interpolate(method='pchip', order=3)\n",
    "df['PotMean']=df['PotMean'].fillna(method='backfill')\n",
    "\n",
    "df['VelRotorMean']=df['VelRotorMean'].interpolate(method='pchip', order=3)\n",
    "df['VelRotorMean']=df['VelRotorMean'].fillna(method='backfill')\n",
    "\n",
    "df['TempEjeLento_1']=df['TempEjeLento_1'].fillna(method='ffill')\n",
    "df['TempRodamMultipMean']=df['TempRodamMultipMean'].fillna(method='ffill')\n",
    "df['TempCojLAMean']=df['TempCojLAMean'].fillna(method='ffill')\n",
    "df['TempCojLOAMean']=df['TempCojLOAMean'].fillna(method='ffill')\n",
    "df['TempGenMean']=df['TempGenMean'].fillna(method='ffill')\n",
    "df['PotMean']=df['PotMean'].fillna(method='ffill')\n",
    "df['VelRotorMean']=df['VelRotorMean'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_listos=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>2013-01-01 00:10:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>2013-01-01 00:20:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>2013-01-01 00:30:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>2013-01-01 00:40:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>2013-01-01 00:50:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357984</th>\n",
       "      <td>-4.154819e+08</td>\n",
       "      <td>2019-10-28 00:10:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357985</th>\n",
       "      <td>-4.155084e+08</td>\n",
       "      <td>2019-10-28 00:20:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357986</th>\n",
       "      <td>-4.155348e+08</td>\n",
       "      <td>2019-10-28 00:30:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357987</th>\n",
       "      <td>-4.155613e+08</td>\n",
       "      <td>2019-10-28 00:40:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357988</th>\n",
       "      <td>-4.155877e+08</td>\n",
       "      <td>2019-10-28 00:50:00.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357989 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TempEjeLento_1              date_time\n",
       "0         2.197280e+01  2013-01-01 00:10:00.0\n",
       "1         2.197280e+01  2013-01-01 00:20:00.0\n",
       "2         2.197280e+01  2013-01-01 00:30:00.0\n",
       "3         2.197280e+01  2013-01-01 00:40:00.0\n",
       "4         2.197280e+01  2013-01-01 00:50:00.0\n",
       "...                ...                    ...\n",
       "357984   -4.154819e+08  2019-10-28 00:10:00.0\n",
       "357985   -4.155084e+08  2019-10-28 00:20:00.0\n",
       "357986   -4.155348e+08  2019-10-28 00:30:00.0\n",
       "357987   -4.155613e+08  2019-10-28 00:40:00.0\n",
       "357988   -4.155877e+08  2019-10-28 00:50:00.0\n",
       "\n",
       "[357989 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_t=pd.DataFrame({ 'TempEjeLento_1':df['TempEjeLento_1'],'date_time': df['date_time'] ,})\n",
    "datos_t.drop([0], inplace=True)\n",
    "datos_t.reset_index(drop=True, inplace=True)\n",
    "datos_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357984</th>\n",
       "      <td>-4.154555e+08</td>\n",
       "      <td>19.34880</td>\n",
       "      <td>57.1155</td>\n",
       "      <td>37.8026</td>\n",
       "      <td>57.4909</td>\n",
       "      <td>149.905</td>\n",
       "      <td>11.6041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357985</th>\n",
       "      <td>-4.154819e+08</td>\n",
       "      <td>19.28660</td>\n",
       "      <td>57.9033</td>\n",
       "      <td>37.8422</td>\n",
       "      <td>58.0973</td>\n",
       "      <td>187.893</td>\n",
       "      <td>12.0709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357986</th>\n",
       "      <td>-4.155084e+08</td>\n",
       "      <td>19.22430</td>\n",
       "      <td>58.6912</td>\n",
       "      <td>37.8818</td>\n",
       "      <td>58.7037</td>\n",
       "      <td>192.204</td>\n",
       "      <td>12.0428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357987</th>\n",
       "      <td>-4.155348e+08</td>\n",
       "      <td>19.16210</td>\n",
       "      <td>59.4790</td>\n",
       "      <td>37.9214</td>\n",
       "      <td>59.1127</td>\n",
       "      <td>170.627</td>\n",
       "      <td>11.7507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357988</th>\n",
       "      <td>-4.155613e+08</td>\n",
       "      <td>19.09980</td>\n",
       "      <td>60.2669</td>\n",
       "      <td>37.9610</td>\n",
       "      <td>59.2432</td>\n",
       "      <td>192.638</td>\n",
       "      <td>12.1077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357989 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TempEjeLento_1-1  TempAmbMean-1  TempRodamMultipMean-1  \\\n",
       "0           2.197280e+01        3.61457                57.1665   \n",
       "1           2.197280e+01        3.61457                57.1665   \n",
       "2           2.197280e+01        3.61457                57.1665   \n",
       "3           2.197280e+01        3.61457                57.1665   \n",
       "4           2.197280e+01        3.61457                57.1665   \n",
       "...                  ...            ...                    ...   \n",
       "357984     -4.154555e+08       19.34880                57.1155   \n",
       "357985     -4.154819e+08       19.28660                57.9033   \n",
       "357986     -4.155084e+08       19.22430                58.6912   \n",
       "357987     -4.155348e+08       19.16210                59.4790   \n",
       "357988     -4.155613e+08       19.09980                60.2669   \n",
       "\n",
       "        TempCojLOAMean-1  TempGenMean-1  PotMean-1  VelRotorMean-1  \n",
       "0                14.9397        36.0982    219.280         11.9272  \n",
       "1                14.9397        36.0982    219.280         11.9272  \n",
       "2                14.9397        36.0982    219.280         11.9272  \n",
       "3                14.9397        36.0982    219.280         11.9272  \n",
       "4                14.9397        36.0982    219.280         11.9272  \n",
       "...                  ...            ...        ...             ...  \n",
       "357984           37.8026        57.4909    149.905         11.6041  \n",
       "357985           37.8422        58.0973    187.893         12.0709  \n",
       "357986           37.8818        58.7037    192.204         12.0428  \n",
       "357987           37.9214        59.1127    170.627         11.7507  \n",
       "357988           37.9610        59.2432    192.638         12.1077  \n",
       "\n",
       "[357989 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_tmenos1=pd.DataFrame({'TempEjeLento_1-1': df['TempEjeLento_1'],'TempAmbMean-1': df['TempAmbMean'], 'TempRodamMultipMean-1': df['TempRodamMultipMean'],'TempCojLOAMean-1': df['TempCojLOAMean'], 'TempGenMean-1': df['TempGenMean'], 'PotMean-1': df['PotMean'], 'VelRotorMean-1': df['VelRotorMean']})\n",
    "datos_tmenos1.drop([len(df['VelRotorMean'])-1], inplace=True)\n",
    "datos_tmenos1.reset_index(drop=True, inplace=True)\n",
    "datos_tmenos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:10:00.0</td>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "      <td>2.197280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 00:20:00.0</td>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "      <td>2.197280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 00:30:00.0</td>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "      <td>2.197280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 00:40:00.0</td>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "      <td>2.197280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 00:50:00.0</td>\n",
       "      <td>2.197280e+01</td>\n",
       "      <td>3.61457</td>\n",
       "      <td>57.1665</td>\n",
       "      <td>14.9397</td>\n",
       "      <td>36.0982</td>\n",
       "      <td>219.280</td>\n",
       "      <td>11.9272</td>\n",
       "      <td>2.197280e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357984</th>\n",
       "      <td>2019-10-28 00:10:00.0</td>\n",
       "      <td>-4.154555e+08</td>\n",
       "      <td>19.34880</td>\n",
       "      <td>57.1155</td>\n",
       "      <td>37.8026</td>\n",
       "      <td>57.4909</td>\n",
       "      <td>149.905</td>\n",
       "      <td>11.6041</td>\n",
       "      <td>-4.154819e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357985</th>\n",
       "      <td>2019-10-28 00:20:00.0</td>\n",
       "      <td>-4.154819e+08</td>\n",
       "      <td>19.28660</td>\n",
       "      <td>57.9033</td>\n",
       "      <td>37.8422</td>\n",
       "      <td>58.0973</td>\n",
       "      <td>187.893</td>\n",
       "      <td>12.0709</td>\n",
       "      <td>-4.155084e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357986</th>\n",
       "      <td>2019-10-28 00:30:00.0</td>\n",
       "      <td>-4.155084e+08</td>\n",
       "      <td>19.22430</td>\n",
       "      <td>58.6912</td>\n",
       "      <td>37.8818</td>\n",
       "      <td>58.7037</td>\n",
       "      <td>192.204</td>\n",
       "      <td>12.0428</td>\n",
       "      <td>-4.155348e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357987</th>\n",
       "      <td>2019-10-28 00:40:00.0</td>\n",
       "      <td>-4.155348e+08</td>\n",
       "      <td>19.16210</td>\n",
       "      <td>59.4790</td>\n",
       "      <td>37.9214</td>\n",
       "      <td>59.1127</td>\n",
       "      <td>170.627</td>\n",
       "      <td>11.7507</td>\n",
       "      <td>-4.155613e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357988</th>\n",
       "      <td>2019-10-28 00:50:00.0</td>\n",
       "      <td>-4.155613e+08</td>\n",
       "      <td>19.09980</td>\n",
       "      <td>60.2669</td>\n",
       "      <td>37.9610</td>\n",
       "      <td>59.2432</td>\n",
       "      <td>192.638</td>\n",
       "      <td>12.1077</td>\n",
       "      <td>-4.155877e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357989 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date_time  TempEjeLento_1-1  TempAmbMean-1  \\\n",
       "0       2013-01-01 00:10:00.0      2.197280e+01        3.61457   \n",
       "1       2013-01-01 00:20:00.0      2.197280e+01        3.61457   \n",
       "2       2013-01-01 00:30:00.0      2.197280e+01        3.61457   \n",
       "3       2013-01-01 00:40:00.0      2.197280e+01        3.61457   \n",
       "4       2013-01-01 00:50:00.0      2.197280e+01        3.61457   \n",
       "...                       ...               ...            ...   \n",
       "357984  2019-10-28 00:10:00.0     -4.154555e+08       19.34880   \n",
       "357985  2019-10-28 00:20:00.0     -4.154819e+08       19.28660   \n",
       "357986  2019-10-28 00:30:00.0     -4.155084e+08       19.22430   \n",
       "357987  2019-10-28 00:40:00.0     -4.155348e+08       19.16210   \n",
       "357988  2019-10-28 00:50:00.0     -4.155613e+08       19.09980   \n",
       "\n",
       "        TempRodamMultipMean-1  TempCojLOAMean-1  TempGenMean-1  PotMean-1  \\\n",
       "0                     57.1665           14.9397        36.0982    219.280   \n",
       "1                     57.1665           14.9397        36.0982    219.280   \n",
       "2                     57.1665           14.9397        36.0982    219.280   \n",
       "3                     57.1665           14.9397        36.0982    219.280   \n",
       "4                     57.1665           14.9397        36.0982    219.280   \n",
       "...                       ...               ...            ...        ...   \n",
       "357984                57.1155           37.8026        57.4909    149.905   \n",
       "357985                57.9033           37.8422        58.0973    187.893   \n",
       "357986                58.6912           37.8818        58.7037    192.204   \n",
       "357987                59.4790           37.9214        59.1127    170.627   \n",
       "357988                60.2669           37.9610        59.2432    192.638   \n",
       "\n",
       "        VelRotorMean-1  TempEjeLento_1  \n",
       "0              11.9272    2.197280e+01  \n",
       "1              11.9272    2.197280e+01  \n",
       "2              11.9272    2.197280e+01  \n",
       "3              11.9272    2.197280e+01  \n",
       "4              11.9272    2.197280e+01  \n",
       "...                ...             ...  \n",
       "357984         11.6041   -4.154819e+08  \n",
       "357985         12.0709   -4.155084e+08  \n",
       "357986         12.0428   -4.155348e+08  \n",
       "357987         11.7507   -4.155613e+08  \n",
       "357988         12.1077   -4.155877e+08  \n",
       "\n",
       "[357989 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_listos=pd.DataFrame({'date_time': datos_t['date_time'], 'TempEjeLento_1-1': datos_tmenos1['TempEjeLento_1-1'],'TempAmbMean-1': datos_tmenos1['TempAmbMean-1'],'TempRodamMultipMean-1': datos_tmenos1['TempRodamMultipMean-1'],'TempCojLOAMean-1': datos_tmenos1['TempCojLOAMean-1'],'TempGenMean-1': datos_tmenos1['TempGenMean-1'], 'PotMean-1': datos_tmenos1['PotMean-1'], 'VelRotorMean-1': datos_tmenos1['VelRotorMean-1'],'TempEjeLento_1': datos_t['TempEjeLento_1']})\n",
    "datos_listos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizado(df,a1,b1,a2,b2,a6,b6,a10,b10,a12,b12,a14,b14,a16,b16,a17,b17):\n",
    "    \n",
    "\n",
    "        datos_norm=pd.DataFrame({\"date_time\": df['date_time']})\n",
    "        datos_norm[\"TempEjeLento_1-1\"] = (df['TempEjeLento_1-1']-b1)/(a1-b1)\n",
    "        datos_norm[\"TempAmbMean-1\"]= (df['TempAmbMean-1']-b2)/(a2-b2)\n",
    "        datos_norm[\"TempRodamMultipMean-1\"] = (df['TempRodamMultipMean-1']-b6)/(a6-b6)\n",
    "        #datos_norm[\"TempCojLAMean-1\"] = (df['TempCojLAMean-1']-b8)/(a8-b8) \n",
    "        datos_norm[\"TempCojLOAMean-1\"] = (df['TempCojLOAMean-1']-b10)/(a10-b10) \n",
    "        datos_norm[\"TempGenMean-1\"] = (df['TempGenMean-1']-b12)/(a12-b12)\n",
    "        datos_norm[\"PotMean-1\"] = (df['PotMean-1']-b14)/(a14-b14) \n",
    "        datos_norm[\"VelRotorMean-1\"] = (df['VelRotorMean-1']-b16)/(a16-b16)\n",
    "        datos_norm[\"TempEjeLento_1\"] = (df['TempEjeLento_1']-b17)/(a17-b17)\n",
    "        #datos_norm['date_time'] = df['date_time']\n",
    "\n",
    "        return datos_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta\n",
    "datos_listos['date_time']=pd.to_datetime(datos_listos['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tv=datos_listos.copy()\n",
    "mask = ((data_tv['date_time'] >= '2017-02-06 00:00:00') & (data_tv['date_time'] < '2018-01-01 00:00:00') ) \n",
    "train_tv=data_tv.loc[mask]\n",
    "train_tv.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longitud=len(train_tv)\n",
    "#longitud=longitud*70/100\n",
    "longitud=(longitud)/144\n",
    "longitud=longitud*90/100\n",
    "longitud=round(longitud)\n",
    "longitud=longitud*144\n",
    "longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>23.454597</td>\n",
       "      <td>5.29548</td>\n",
       "      <td>67.9703</td>\n",
       "      <td>35.0589</td>\n",
       "      <td>84.2192</td>\n",
       "      <td>1463.170</td>\n",
       "      <td>17.2516</td>\n",
       "      <td>23.461126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-06 00:10:00</td>\n",
       "      <td>23.461126</td>\n",
       "      <td>5.23856</td>\n",
       "      <td>67.9609</td>\n",
       "      <td>34.9657</td>\n",
       "      <td>84.7324</td>\n",
       "      <td>1523.240</td>\n",
       "      <td>17.0297</td>\n",
       "      <td>23.467660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-06 00:20:00</td>\n",
       "      <td>23.467660</td>\n",
       "      <td>5.18163</td>\n",
       "      <td>67.9516</td>\n",
       "      <td>34.8724</td>\n",
       "      <td>85.2455</td>\n",
       "      <td>1525.110</td>\n",
       "      <td>16.9288</td>\n",
       "      <td>23.474198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-06 00:30:00</td>\n",
       "      <td>23.474198</td>\n",
       "      <td>5.12471</td>\n",
       "      <td>67.9422</td>\n",
       "      <td>34.7791</td>\n",
       "      <td>85.7587</td>\n",
       "      <td>1510.910</td>\n",
       "      <td>17.0879</td>\n",
       "      <td>23.480740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-06 00:40:00</td>\n",
       "      <td>23.480740</td>\n",
       "      <td>5.06779</td>\n",
       "      <td>67.9329</td>\n",
       "      <td>34.6858</td>\n",
       "      <td>86.2718</td>\n",
       "      <td>1523.620</td>\n",
       "      <td>16.7273</td>\n",
       "      <td>23.487286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42619</th>\n",
       "      <td>2017-11-28 23:10:00</td>\n",
       "      <td>22.570200</td>\n",
       "      <td>9.21998</td>\n",
       "      <td>66.7897</td>\n",
       "      <td>29.5458</td>\n",
       "      <td>52.8007</td>\n",
       "      <td>627.165</td>\n",
       "      <td>16.1957</td>\n",
       "      <td>22.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42620</th>\n",
       "      <td>2017-11-28 23:20:00</td>\n",
       "      <td>22.644600</td>\n",
       "      <td>9.23035</td>\n",
       "      <td>66.6943</td>\n",
       "      <td>29.5943</td>\n",
       "      <td>53.4073</td>\n",
       "      <td>668.174</td>\n",
       "      <td>16.5365</td>\n",
       "      <td>22.709300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42621</th>\n",
       "      <td>2017-11-28 23:30:00</td>\n",
       "      <td>22.709300</td>\n",
       "      <td>9.24072</td>\n",
       "      <td>66.5989</td>\n",
       "      <td>29.6428</td>\n",
       "      <td>54.0139</td>\n",
       "      <td>756.345</td>\n",
       "      <td>16.9779</td>\n",
       "      <td>22.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42622</th>\n",
       "      <td>2017-11-28 23:40:00</td>\n",
       "      <td>22.774000</td>\n",
       "      <td>9.25109</td>\n",
       "      <td>66.5252</td>\n",
       "      <td>29.6913</td>\n",
       "      <td>54.6205</td>\n",
       "      <td>881.859</td>\n",
       "      <td>17.6032</td>\n",
       "      <td>22.838700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42623</th>\n",
       "      <td>2017-11-28 23:50:00</td>\n",
       "      <td>22.838700</td>\n",
       "      <td>9.26146</td>\n",
       "      <td>66.5445</td>\n",
       "      <td>29.7398</td>\n",
       "      <td>55.2271</td>\n",
       "      <td>985.070</td>\n",
       "      <td>17.8718</td>\n",
       "      <td>22.903400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42624 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  TempEjeLento_1-1  TempAmbMean-1  \\\n",
       "0     2017-02-06 00:00:00         23.454597        5.29548   \n",
       "1     2017-02-06 00:10:00         23.461126        5.23856   \n",
       "2     2017-02-06 00:20:00         23.467660        5.18163   \n",
       "3     2017-02-06 00:30:00         23.474198        5.12471   \n",
       "4     2017-02-06 00:40:00         23.480740        5.06779   \n",
       "...                   ...               ...            ...   \n",
       "42619 2017-11-28 23:10:00         22.570200        9.21998   \n",
       "42620 2017-11-28 23:20:00         22.644600        9.23035   \n",
       "42621 2017-11-28 23:30:00         22.709300        9.24072   \n",
       "42622 2017-11-28 23:40:00         22.774000        9.25109   \n",
       "42623 2017-11-28 23:50:00         22.838700        9.26146   \n",
       "\n",
       "       TempRodamMultipMean-1  TempCojLOAMean-1  TempGenMean-1  PotMean-1  \\\n",
       "0                    67.9703           35.0589        84.2192   1463.170   \n",
       "1                    67.9609           34.9657        84.7324   1523.240   \n",
       "2                    67.9516           34.8724        85.2455   1525.110   \n",
       "3                    67.9422           34.7791        85.7587   1510.910   \n",
       "4                    67.9329           34.6858        86.2718   1523.620   \n",
       "...                      ...               ...            ...        ...   \n",
       "42619                66.7897           29.5458        52.8007    627.165   \n",
       "42620                66.6943           29.5943        53.4073    668.174   \n",
       "42621                66.5989           29.6428        54.0139    756.345   \n",
       "42622                66.5252           29.6913        54.6205    881.859   \n",
       "42623                66.5445           29.7398        55.2271    985.070   \n",
       "\n",
       "       VelRotorMean-1  TempEjeLento_1  \n",
       "0             17.2516       23.461126  \n",
       "1             17.0297       23.467660  \n",
       "2             16.9288       23.474198  \n",
       "3             17.0879       23.480740  \n",
       "4             16.7273       23.487286  \n",
       "...               ...             ...  \n",
       "42619         16.1957       22.644600  \n",
       "42620         16.5365       22.709300  \n",
       "42621         16.9779       22.774000  \n",
       "42622         17.6032       22.838700  \n",
       "42623         17.8718       22.903400  \n",
       "\n",
       "[42624 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training=train_tv.loc[0:round(longitud)-1]\n",
    "training.reset_index(drop=True, inplace=True)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "df=training\n",
    "\n",
    "a1=df['TempEjeLento_1-1'].values.max()\n",
    "b1=df['TempEjeLento_1-1'].values.min()\n",
    "a2=df['TempAmbMean-1'].values.max()\n",
    "b2=df['TempAmbMean-1'].values.min()\n",
    "a6=df['TempRodamMultipMean-1'].values.max()\n",
    "b6=df['TempRodamMultipMean-1'].values.min()\n",
    "#a8=df['TempCojLAMean-1'].values.max()\n",
    "#b8=df['TempCojLAMean-1'].values.min()\n",
    "a10=df['TempCojLOAMean-1'].values.max()\n",
    "b10=df['TempCojLOAMean-1'].values.min()\n",
    "a12=df['TempGenMean-1'].values.max()\n",
    "b12=df['TempGenMean-1'].values.min()\n",
    "a14=df['PotMean-1'].values.max()\n",
    "b14=df['PotMean-1'].values.min()\n",
    "a16=df['VelRotorMean-1'].values.max()\n",
    "b16=df['VelRotorMean-1'].values.min()\n",
    "a17=df['TempEjeLento_1'].values.max()\n",
    "b17=df['TempEjeLento_1'].values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-02-06 00:00:00</td>\n",
       "      <td>0.451348</td>\n",
       "      <td>0.097159</td>\n",
       "      <td>0.841016</td>\n",
       "      <td>0.324844</td>\n",
       "      <td>0.632134</td>\n",
       "      <td>0.951457</td>\n",
       "      <td>0.945014</td>\n",
       "      <td>0.451580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-06 00:10:00</td>\n",
       "      <td>0.451580</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>0.840852</td>\n",
       "      <td>0.323214</td>\n",
       "      <td>0.637375</td>\n",
       "      <td>0.990519</td>\n",
       "      <td>0.932858</td>\n",
       "      <td>0.451812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-02-06 00:20:00</td>\n",
       "      <td>0.451812</td>\n",
       "      <td>0.094195</td>\n",
       "      <td>0.840690</td>\n",
       "      <td>0.321583</td>\n",
       "      <td>0.642615</td>\n",
       "      <td>0.991735</td>\n",
       "      <td>0.927331</td>\n",
       "      <td>0.452044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-02-06 00:30:00</td>\n",
       "      <td>0.452044</td>\n",
       "      <td>0.092713</td>\n",
       "      <td>0.840525</td>\n",
       "      <td>0.319952</td>\n",
       "      <td>0.647857</td>\n",
       "      <td>0.982501</td>\n",
       "      <td>0.936046</td>\n",
       "      <td>0.452277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-06 00:40:00</td>\n",
       "      <td>0.452277</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>0.840363</td>\n",
       "      <td>0.318321</td>\n",
       "      <td>0.653097</td>\n",
       "      <td>0.990766</td>\n",
       "      <td>0.916293</td>\n",
       "      <td>0.452509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42619</th>\n",
       "      <td>2017-11-28 23:10:00</td>\n",
       "      <td>0.419938</td>\n",
       "      <td>0.199339</td>\n",
       "      <td>0.820387</td>\n",
       "      <td>0.228460</td>\n",
       "      <td>0.311251</td>\n",
       "      <td>0.407827</td>\n",
       "      <td>0.887173</td>\n",
       "      <td>0.422580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42620</th>\n",
       "      <td>2017-11-28 23:20:00</td>\n",
       "      <td>0.422580</td>\n",
       "      <td>0.199609</td>\n",
       "      <td>0.818720</td>\n",
       "      <td>0.229308</td>\n",
       "      <td>0.317446</td>\n",
       "      <td>0.434494</td>\n",
       "      <td>0.905842</td>\n",
       "      <td>0.424878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42621</th>\n",
       "      <td>2017-11-28 23:30:00</td>\n",
       "      <td>0.424878</td>\n",
       "      <td>0.199879</td>\n",
       "      <td>0.817053</td>\n",
       "      <td>0.230156</td>\n",
       "      <td>0.323641</td>\n",
       "      <td>0.491829</td>\n",
       "      <td>0.930021</td>\n",
       "      <td>0.427176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42622</th>\n",
       "      <td>2017-11-28 23:40:00</td>\n",
       "      <td>0.427176</td>\n",
       "      <td>0.200149</td>\n",
       "      <td>0.815765</td>\n",
       "      <td>0.231004</td>\n",
       "      <td>0.329837</td>\n",
       "      <td>0.573447</td>\n",
       "      <td>0.964274</td>\n",
       "      <td>0.429474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42623</th>\n",
       "      <td>2017-11-28 23:50:00</td>\n",
       "      <td>0.429474</td>\n",
       "      <td>0.200419</td>\n",
       "      <td>0.816103</td>\n",
       "      <td>0.231852</td>\n",
       "      <td>0.336032</td>\n",
       "      <td>0.640563</td>\n",
       "      <td>0.978987</td>\n",
       "      <td>0.431772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42624 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  TempEjeLento_1-1  TempAmbMean-1  \\\n",
       "0     2017-02-06 00:00:00          0.451348       0.097159   \n",
       "1     2017-02-06 00:10:00          0.451580       0.095677   \n",
       "2     2017-02-06 00:20:00          0.451812       0.094195   \n",
       "3     2017-02-06 00:30:00          0.452044       0.092713   \n",
       "4     2017-02-06 00:40:00          0.452277       0.091231   \n",
       "...                   ...               ...            ...   \n",
       "42619 2017-11-28 23:10:00          0.419938       0.199339   \n",
       "42620 2017-11-28 23:20:00          0.422580       0.199609   \n",
       "42621 2017-11-28 23:30:00          0.424878       0.199879   \n",
       "42622 2017-11-28 23:40:00          0.427176       0.200149   \n",
       "42623 2017-11-28 23:50:00          0.429474       0.200419   \n",
       "\n",
       "       TempRodamMultipMean-1  TempCojLOAMean-1  TempGenMean-1  PotMean-1  \\\n",
       "0                   0.841016          0.324844       0.632134   0.951457   \n",
       "1                   0.840852          0.323214       0.637375   0.990519   \n",
       "2                   0.840690          0.321583       0.642615   0.991735   \n",
       "3                   0.840525          0.319952       0.647857   0.982501   \n",
       "4                   0.840363          0.318321       0.653097   0.990766   \n",
       "...                      ...               ...            ...        ...   \n",
       "42619               0.820387          0.228460       0.311251   0.407827   \n",
       "42620               0.818720          0.229308       0.317446   0.434494   \n",
       "42621               0.817053          0.230156       0.323641   0.491829   \n",
       "42622               0.815765          0.231004       0.329837   0.573447   \n",
       "42623               0.816103          0.231852       0.336032   0.640563   \n",
       "\n",
       "       VelRotorMean-1  TempEjeLento_1  \n",
       "0            0.945014        0.451580  \n",
       "1            0.932858        0.451812  \n",
       "2            0.927331        0.452044  \n",
       "3            0.936046        0.452277  \n",
       "4            0.916293        0.452509  \n",
       "...               ...             ...  \n",
       "42619        0.887173        0.422580  \n",
       "42620        0.905842        0.424878  \n",
       "42621        0.930021        0.427176  \n",
       "42622        0.964274        0.429474  \n",
       "42623        0.978987        0.431772  \n",
       "\n",
       "[42624 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training=normalizado(training,a1,b1,a2,b2,a6,b6,a10,b10,a12,b12,a14,b14,a16,b16,a17,b17)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-29 00:00:00</td>\n",
       "      <td>-0.366331</td>\n",
       "      <td>-0.035490</td>\n",
       "      <td>-0.332400</td>\n",
       "      <td>-0.284011</td>\n",
       "      <td>-0.224517</td>\n",
       "      <td>3.551666e-04</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>-0.366260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-29 00:10:00</td>\n",
       "      <td>-0.366260</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>-0.332391</td>\n",
       "      <td>-0.283996</td>\n",
       "      <td>-0.224454</td>\n",
       "      <td>4.304555e-04</td>\n",
       "      <td>0.053740</td>\n",
       "      <td>-0.366195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-29 00:20:00</td>\n",
       "      <td>-0.366195</td>\n",
       "      <td>-0.035476</td>\n",
       "      <td>-0.332382</td>\n",
       "      <td>-0.283982</td>\n",
       "      <td>-0.224391</td>\n",
       "      <td>3.683418e-04</td>\n",
       "      <td>0.052945</td>\n",
       "      <td>-0.366131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-29 00:30:00</td>\n",
       "      <td>-0.366131</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>-0.332373</td>\n",
       "      <td>-0.283967</td>\n",
       "      <td>-0.224327</td>\n",
       "      <td>3.378267e-04</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>-0.366067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-29 00:40:00</td>\n",
       "      <td>-0.366067</td>\n",
       "      <td>-0.035462</td>\n",
       "      <td>-0.332363</td>\n",
       "      <td>-0.283952</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>3.893250e-04</td>\n",
       "      <td>0.053640</td>\n",
       "      <td>-0.366003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>2017-12-31 23:10:00</td>\n",
       "      <td>-0.372426</td>\n",
       "      <td>-0.038153</td>\n",
       "      <td>-0.336014</td>\n",
       "      <td>-0.282081</td>\n",
       "      <td>-0.221441</td>\n",
       "      <td>2.914076e-05</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>-0.372670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>2017-12-31 23:20:00</td>\n",
       "      <td>-0.372670</td>\n",
       "      <td>-0.038191</td>\n",
       "      <td>-0.336467</td>\n",
       "      <td>-0.282139</td>\n",
       "      <td>-0.221677</td>\n",
       "      <td>4.116001e-07</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.372914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>2017-12-31 23:30:00</td>\n",
       "      <td>-0.372914</td>\n",
       "      <td>-0.038229</td>\n",
       "      <td>-0.336853</td>\n",
       "      <td>-0.282213</td>\n",
       "      <td>-0.221914</td>\n",
       "      <td>3.992257e-07</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>-0.373169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>2017-12-31 23:40:00</td>\n",
       "      <td>-0.373169</td>\n",
       "      <td>-0.038267</td>\n",
       "      <td>-0.337238</td>\n",
       "      <td>-0.282373</td>\n",
       "      <td>-0.222150</td>\n",
       "      <td>3.868518e-07</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>-0.373485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>2017-12-31 23:50:00</td>\n",
       "      <td>-0.373485</td>\n",
       "      <td>-0.038305</td>\n",
       "      <td>-0.337624</td>\n",
       "      <td>-0.282546</td>\n",
       "      <td>-0.222383</td>\n",
       "      <td>3.744774e-07</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>-0.373809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4752 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_time  TempEjeLento_1-1  TempAmbMean-1  \\\n",
       "0    2017-11-29 00:00:00         -0.366331      -0.035490   \n",
       "1    2017-11-29 00:10:00         -0.366260      -0.035483   \n",
       "2    2017-11-29 00:20:00         -0.366195      -0.035476   \n",
       "3    2017-11-29 00:30:00         -0.366131      -0.035469   \n",
       "4    2017-11-29 00:40:00         -0.366067      -0.035462   \n",
       "...                  ...               ...            ...   \n",
       "4747 2017-12-31 23:10:00         -0.372426      -0.038153   \n",
       "4748 2017-12-31 23:20:00         -0.372670      -0.038191   \n",
       "4749 2017-12-31 23:30:00         -0.372914      -0.038229   \n",
       "4750 2017-12-31 23:40:00         -0.373169      -0.038267   \n",
       "4751 2017-12-31 23:50:00         -0.373485      -0.038305   \n",
       "\n",
       "      TempRodamMultipMean-1  TempCojLOAMean-1  TempGenMean-1     PotMean-1  \\\n",
       "0                 -0.332400         -0.284011      -0.224517  3.551666e-04   \n",
       "1                 -0.332391         -0.283996      -0.224454  4.304555e-04   \n",
       "2                 -0.332382         -0.283982      -0.224391  3.683418e-04   \n",
       "3                 -0.332373         -0.283967      -0.224327  3.378267e-04   \n",
       "4                 -0.332363         -0.283952      -0.224292  3.893250e-04   \n",
       "...                     ...               ...            ...           ...   \n",
       "4747              -0.336014         -0.282081      -0.221441  2.914076e-05   \n",
       "4748              -0.336467         -0.282139      -0.221677  4.116001e-07   \n",
       "4749              -0.336853         -0.282213      -0.221914  3.992257e-07   \n",
       "4750              -0.337238         -0.282373      -0.222150  3.868518e-07   \n",
       "4751              -0.337624         -0.282546      -0.222383  3.744774e-07   \n",
       "\n",
       "      VelRotorMean-1  TempEjeLento_1  \n",
       "0           0.051660       -0.366260  \n",
       "1           0.053740       -0.366195  \n",
       "2           0.052945       -0.366131  \n",
       "3           0.052161       -0.366067  \n",
       "4           0.053640       -0.366003  \n",
       "...              ...             ...  \n",
       "4747        0.008195       -0.372670  \n",
       "4748        0.001345       -0.372914  \n",
       "4749        0.001091       -0.373169  \n",
       "4750        0.000995       -0.373485  \n",
       "4751        0.001262       -0.373809  \n",
       "\n",
       "[4752 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation=train_tv.loc[round(longitud):len(train_tv)]\n",
    "validation.reset_index(drop=True, inplace=True)\n",
    "validation=normalizado(validation,a1,b1,a2,b2,a6,b6,a10,b10,a12,b12,a14,b14,a16,b16,a17,b17)\n",
    "validation=normalizado(validation,a1,b1,a2,b2,a6,b6,a10,b10,a12,b12,a14,b14,a16,b16,a17,b17)\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>TempEjeLento_1-1</th>\n",
       "      <th>TempAmbMean-1</th>\n",
       "      <th>TempRodamMultipMean-1</th>\n",
       "      <th>TempCojLOAMean-1</th>\n",
       "      <th>TempGenMean-1</th>\n",
       "      <th>PotMean-1</th>\n",
       "      <th>VelRotorMean-1</th>\n",
       "      <th>TempEjeLento_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0.221229</td>\n",
       "      <td>0.091105</td>\n",
       "      <td>0.495597</td>\n",
       "      <td>0.306660</td>\n",
       "      <td>0.537299</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.019991</td>\n",
       "      <td>0.212105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:10:00</td>\n",
       "      <td>0.212105</td>\n",
       "      <td>0.089639</td>\n",
       "      <td>0.473538</td>\n",
       "      <td>0.296798</td>\n",
       "      <td>0.527147</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.202985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 00:20:00</td>\n",
       "      <td>0.202985</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>0.451481</td>\n",
       "      <td>0.286934</td>\n",
       "      <td>0.516994</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.017928</td>\n",
       "      <td>0.193861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 00:30:00</td>\n",
       "      <td>0.193861</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.429422</td>\n",
       "      <td>0.277072</td>\n",
       "      <td>0.506841</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>0.185394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 00:40:00</td>\n",
       "      <td>0.185394</td>\n",
       "      <td>0.085238</td>\n",
       "      <td>0.407379</td>\n",
       "      <td>0.267210</td>\n",
       "      <td>0.496688</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.178582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47803</th>\n",
       "      <td>2018-11-30 23:10:00</td>\n",
       "      <td>0.305608</td>\n",
       "      <td>0.116605</td>\n",
       "      <td>0.587952</td>\n",
       "      <td>0.126475</td>\n",
       "      <td>0.212243</td>\n",
       "      <td>0.040475</td>\n",
       "      <td>0.638326</td>\n",
       "      <td>0.304028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47804</th>\n",
       "      <td>2018-11-30 23:20:00</td>\n",
       "      <td>0.304028</td>\n",
       "      <td>0.116073</td>\n",
       "      <td>0.587146</td>\n",
       "      <td>0.125982</td>\n",
       "      <td>0.211926</td>\n",
       "      <td>0.058854</td>\n",
       "      <td>0.637324</td>\n",
       "      <td>0.302451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47805</th>\n",
       "      <td>2018-11-30 23:30:00</td>\n",
       "      <td>0.302451</td>\n",
       "      <td>0.115541</td>\n",
       "      <td>0.579079</td>\n",
       "      <td>0.125489</td>\n",
       "      <td>0.211608</td>\n",
       "      <td>0.051025</td>\n",
       "      <td>0.640309</td>\n",
       "      <td>0.300476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47806</th>\n",
       "      <td>2018-11-30 23:40:00</td>\n",
       "      <td>0.300476</td>\n",
       "      <td>0.115008</td>\n",
       "      <td>0.567499</td>\n",
       "      <td>0.124996</td>\n",
       "      <td>0.211290</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>0.643010</td>\n",
       "      <td>0.298111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47807</th>\n",
       "      <td>2018-11-30 23:50:00</td>\n",
       "      <td>0.298111</td>\n",
       "      <td>0.114476</td>\n",
       "      <td>0.555919</td>\n",
       "      <td>0.124503</td>\n",
       "      <td>0.210973</td>\n",
       "      <td>0.036154</td>\n",
       "      <td>0.637767</td>\n",
       "      <td>0.295746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47808 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time  TempEjeLento_1-1  TempAmbMean-1  \\\n",
       "0     2018-01-01 00:00:00          0.221229       0.091105   \n",
       "1     2018-01-01 00:10:00          0.212105       0.089639   \n",
       "2     2018-01-01 00:20:00          0.202985       0.088172   \n",
       "3     2018-01-01 00:30:00          0.193861       0.086705   \n",
       "4     2018-01-01 00:40:00          0.185394       0.085238   \n",
       "...                   ...               ...            ...   \n",
       "47803 2018-11-30 23:10:00          0.305608       0.116605   \n",
       "47804 2018-11-30 23:20:00          0.304028       0.116073   \n",
       "47805 2018-11-30 23:30:00          0.302451       0.115541   \n",
       "47806 2018-11-30 23:40:00          0.300476       0.115008   \n",
       "47807 2018-11-30 23:50:00          0.298111       0.114476   \n",
       "\n",
       "       TempRodamMultipMean-1  TempCojLOAMean-1  TempGenMean-1  PotMean-1  \\\n",
       "0                   0.495597          0.306660       0.537299   0.000557   \n",
       "1                   0.473538          0.296798       0.527147   0.000545   \n",
       "2                   0.451481          0.286934       0.516994   0.000527   \n",
       "3                   0.429422          0.277072       0.506841   0.000509   \n",
       "4                   0.407379          0.267210       0.496688   0.000491   \n",
       "...                      ...               ...            ...        ...   \n",
       "47803               0.587952          0.126475       0.212243   0.040475   \n",
       "47804               0.587146          0.125982       0.211926   0.058854   \n",
       "47805               0.579079          0.125489       0.211608   0.051025   \n",
       "47806               0.567499          0.124996       0.211290   0.027133   \n",
       "47807               0.555919          0.124503       0.210973   0.036154   \n",
       "\n",
       "       VelRotorMean-1  TempEjeLento_1  \n",
       "0            0.019991        0.212105  \n",
       "1            0.011979        0.202985  \n",
       "2            0.017928        0.193861  \n",
       "3            0.022091        0.185394  \n",
       "4            0.022888        0.178582  \n",
       "...               ...             ...  \n",
       "47803        0.638326        0.304028  \n",
       "47804        0.637324        0.302451  \n",
       "47805        0.640309        0.300476  \n",
       "47806        0.643010        0.298111  \n",
       "47807        0.637767        0.295746  \n",
       "\n",
       "[47808 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=datos_listos.copy()\n",
    "mask = ((test['date_time'] >= '2018-01-01 00:00:00') & (test['date_time'] < '2018-12-01 00:00:00')) \n",
    "test=test.loc[mask]\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test=normalizado(test,a1,b1,a2,b2,a6,b6,a10,b10,a12,b12,a14,b14,a16,b16,a17,b17)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "\n",
    "def datosstack(data):\n",
    "    \n",
    "        X1 = array(data['TempAmbMean-1'])\n",
    "        X2 = array(data['TempRodamMultipMean-1'])\n",
    "        #X3 = array(data['TempCojLAMean-1'])\n",
    "        X3 = array(data['TempCojLOAMean-1'])\n",
    "        X4 = array(data['TempGenMean-1'])\n",
    "        X5 = array(data['PotMean-1'])\n",
    "        X6 = array(data['VelRotorMean-1'])\n",
    "        X7 = array(data['TempEjeLento_1-1'])\n",
    "        X8 = array(data['TempEjeLento_1'])\n",
    "\n",
    "        X1 = X1.reshape((len(X1), 1))\n",
    "        X2 = X2.reshape((len(X2), 1))\n",
    "        X3 = X3.reshape((len(X3), 1))\n",
    "        X4 = X4.reshape((len(X4), 1))\n",
    "        X5 = X5.reshape((len(X5), 1))\n",
    "        X6 = X6.reshape((len(X6), 1))\n",
    "        X7 = X7.reshape((len(X7), 1))\n",
    "        X8 = X8.reshape((len(X8), 1))\n",
    "        #X9 = X8.reshape((len(X9), 1))\n",
    "        \n",
    "        dataset = hstack((X1, X2, X3, X4, X5, X6, X7, X8))            \n",
    "\n",
    "        return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42624, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train=datosstack(training)\n",
    "dataset_validation=datosstack(validation)\n",
    "dataset_test=datosstack(test)\n",
    "\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        #end_ix = n_steps*i + n_steps\n",
    "        end_ix = i + n_steps\n",
    "        #start_ix = end_ix - n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "            # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42624, 1, 7) (42624,)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1\n",
    "xtrain, ytrain = split_sequences(dataset_train, n_steps)\n",
    "print(xtrain.shape, ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4752, 1, 7) (4752,)\n"
     ]
    }
   ],
   "source": [
    "xvalidation, yvalidation = split_sequences(dataset_validation, n_steps)\n",
    "print(xvalidation.shape, yvalidation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47808, 1, 7) (47808,)\n"
     ]
    }
   ],
   "source": [
    "xtest, ytest = split_sequences(dataset_test, n_steps)\n",
    "print(xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    #x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = inputs\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42624, 1, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_shape = xtrain.shape[1:]\n",
    "\n",
    "    model = build_model(\n",
    "        input_shape,\n",
    "        head_size=256,\n",
    "        num_heads=4,\n",
    "        ff_dim=4,\n",
    "        num_transformer_blocks=4,\n",
    "        mlp_units=[100],\n",
    "        mlp_dropout=0.4,\n",
    "        dropout=0.3,\n",
    "    )\n",
    "    \n",
    "    model.compile(loss=\"mean_squared_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    )\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator = KerasRegressor(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=20, \\\n",
    "    restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning con grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.8 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "btscv = BlockingTimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame()\n",
    "val_loss_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 6816 6817 6818] TEST: [6819 6820 6821 ... 8521 8522 8523]\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 9s 26ms/step - loss: 0.0292 - val_loss: 0.0025\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 0.0086 - val_loss: 0.0011\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0062 - val_loss: 2.9066e-04\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0050 - val_loss: 4.2361e-04\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0045 - val_loss: 5.8545e-04\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 0.0040 - val_loss: 3.7655e-04\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0039 - val_loss: 4.8636e-04\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 0.0034 - val_loss: 2.4149e-04\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0033 - val_loss: 3.7819e-04\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0030 - val_loss: 2.1264e-04\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0026 - val_loss: 2.0694e-04\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0025 - val_loss: 1.1855e-04\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 0.0024 - val_loss: 2.0932e-04\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0022 - val_loss: 2.5195e-04\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 0.0018 - val_loss: 9.1453e-05\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 0.0018 - val_loss: 1.7529e-04\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0015 - val_loss: 1.1126e-04\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 3s 29ms/step - loss: 0.0014 - val_loss: 9.9205e-05\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 2s 22ms/step - loss: 0.0013 - val_loss: 9.3688e-05\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 0.0012 - val_loss: 2.4289e-04\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 0.0011 - val_loss: 8.1854e-05\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 9.8037e-04 - val_loss: 3.4677e-05\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 9.7734e-04 - val_loss: 5.0870e-05\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 8.9497e-04 - val_loss: 2.4342e-05\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 7.9620e-04 - val_loss: 7.6069e-05\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 7.7988e-04 - val_loss: 7.7713e-05\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 7.5336e-04 - val_loss: 3.9507e-05\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 7.0913e-04 - val_loss: 2.0213e-05\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 6.8338e-04 - val_loss: 3.9507e-05\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 6.9005e-04 - val_loss: 4.8833e-05\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 6.9467e-04 - val_loss: 2.6022e-05\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 7.1416e-04 - val_loss: 1.1279e-04\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 6.4985e-04 - val_loss: 1.1700e-04\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 6.3586e-04 - val_loss: 2.0887e-05\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 3s 23ms/step - loss: 6.1819e-04 - val_loss: 4.3340e-05\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.9567e-04 - val_loss: 4.4062e-05\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 5.4232e-04 - val_loss: 6.0610e-05\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.2585e-04 - val_loss: 6.2937e-05\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 5.0453e-04 - val_loss: 6.8910e-05\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.1672e-04 - val_loss: 1.9824e-05\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 5.4932e-04 - val_loss: 5.2486e-05\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.8472e-04 - val_loss: 2.2210e-05\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1675e-04 - val_loss: 1.0457e-05\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.4960e-04 - val_loss: 3.8421e-05\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.3278e-04 - val_loss: 2.2406e-04\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9364e-04 - val_loss: 3.5110e-05\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.5932e-04 - val_loss: 8.5017e-05\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.5119e-04 - val_loss: 1.4906e-05\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0041e-04 - val_loss: 5.1884e-05\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.8914e-04 - val_loss: 2.2019e-05\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.5987e-04 - val_loss: 5.5258e-05\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.4780e-04 - val_loss: 4.8712e-05\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 4.1131e-04 - val_loss: 1.6754e-05\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 4.2107e-04 - val_loss: 8.0993e-05\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.2689e-04 - val_loss: 2.8601e-05\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.2973e-04 - val_loss: 2.3842e-05\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.0862e-04 - val_loss: 2.8937e-05\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.9600e-04 - val_loss: 8.3931e-05\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.0822e-04 - val_loss: 2.7435e-05\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.7981e-04 - val_loss: 2.2050e-05\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.9484e-04 - val_loss: 2.7434e-05\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.8875e-04 - val_loss: 4.4651e-05\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.7681e-04 - val_loss: 1.1400e-04\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.9259e-04 - val_loss: 5.0415e-05\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.2390e-04 - val_loss: 1.5711e-05\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5769e-04 - val_loss: 2.9464e-05\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.6660e-04 - val_loss: 2.4746e-05\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5644e-04 - val_loss: 1.9652e-05\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7576e-04 - val_loss: 4.4711e-05\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7298e-04 - val_loss: 1.4558e-05\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6689e-04 - val_loss: 8.0020e-05\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.8740e-04 - val_loss: 7.1547e-05\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.9201e-04 - val_loss: 2.3417e-05\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5878e-04 - val_loss: 1.8798e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5787e-04 - val_loss: 1.5340e-05\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.8260e-04 - val_loss: 7.5485e-05\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7211e-04 - val_loss: 5.2252e-05\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4665e-04 - val_loss: 1.3591e-05\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5038e-04 - val_loss: 2.7682e-05\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5557e-04 - val_loss: 3.8961e-05\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7750e-04 - val_loss: 9.3550e-06\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5265e-04 - val_loss: 1.6916e-05\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4987e-04 - val_loss: 3.6305e-05\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4152e-04 - val_loss: 6.6107e-05\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.0015e-04 - val_loss: 7.2969e-05\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2279e-04 - val_loss: 1.5936e-05\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2801e-04 - val_loss: 3.3757e-05\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4928e-04 - val_loss: 2.3948e-05\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3528e-04 - val_loss: 4.7367e-05\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.4180e-04 - val_loss: 1.6336e-05\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5865e-04 - val_loss: 1.5155e-05\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3321e-04 - val_loss: 4.6192e-05\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3632e-04 - val_loss: 1.5731e-05\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4770e-04 - val_loss: 2.3926e-05\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6211e-04 - val_loss: 2.7625e-05\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3632e-04 - val_loss: 1.6270e-05\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3188e-04 - val_loss: 3.0173e-05\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2694e-04 - val_loss: 1.1128e-05\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.3242e-04 - val_loss: 1.4555e-05\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.4476e-04 - val_loss: 2.3778e-05\n",
      "TRAIN: [ 8524  8525  8526 ... 15340 15341 15342] TEST: [15343 15344 15345 ... 17045 17046 17047]\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 6.8406e-04 - val_loss: 3.7168e-05\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.7588e-04 - val_loss: 1.6587e-04\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6463e-04 - val_loss: 1.8662e-04\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9564e-04 - val_loss: 5.7465e-05\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0205e-04 - val_loss: 5.4514e-05\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0920e-04 - val_loss: 7.3786e-05\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0043e-04 - val_loss: 2.5976e-04\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7722e-04 - val_loss: 4.3340e-05\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7879e-04 - val_loss: 2.7255e-05\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.6861e-04 - val_loss: 2.5922e-05\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9936e-04 - val_loss: 2.2396e-04\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.6085e-04 - val_loss: 4.7986e-05\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.6274e-04 - val_loss: 4.5840e-05\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.8273e-04 - val_loss: 5.9882e-05\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7207e-04 - val_loss: 1.5650e-04\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0142e-04 - val_loss: 5.4817e-05\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6622e-04 - val_loss: 1.6998e-05\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8487e-04 - val_loss: 1.6171e-04\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9807e-04 - val_loss: 5.3112e-05\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9914e-04 - val_loss: 8.6294e-05\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 3.5571e-04 - val_loss: 1.8061e-04\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.7954e-04 - val_loss: 3.1240e-05\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.7876e-04 - val_loss: 9.4926e-05\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8398e-04 - val_loss: 2.5794e-04\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9390e-04 - val_loss: 5.8263e-05\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7938e-04 - val_loss: 2.1080e-05\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9216e-04 - val_loss: 7.8000e-05\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.6906e-04 - val_loss: 5.4169e-04\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8211e-04 - val_loss: 2.8167e-05\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9046e-04 - val_loss: 5.7159e-05\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7443e-04 - val_loss: 2.7831e-05\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6855e-04 - val_loss: 2.1728e-05\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0289e-04 - val_loss: 2.9903e-04\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8109e-04 - val_loss: 4.7476e-05\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7235e-04 - val_loss: 2.3092e-04\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7285e-04 - val_loss: 3.7392e-05\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7655e-04 - val_loss: 2.9629e-04\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9022e-04 - val_loss: 1.0971e-04\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.5922e-04 - val_loss: 8.1486e-05\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.9783e-04 - val_loss: 4.6178e-05\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6337e-04 - val_loss: 5.2726e-05\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7500e-04 - val_loss: 8.5178e-05\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9595e-04 - val_loss: 5.5867e-04\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.7797e-04 - val_loss: 2.9305e-05\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 3.0481e-04 - val_loss: 1.7240e-04\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.6882e-04 - val_loss: 1.1855e-04\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8326e-04 - val_loss: 1.4180e-04\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7022e-04 - val_loss: 4.2088e-04\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.6806e-04 - val_loss: 2.2561e-05\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.3298e-04 - val_loss: 4.4830e-05\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7747e-04 - val_loss: 3.1228e-04\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.8642e-04 - val_loss: 1.4402e-04\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.6415e-04 - val_loss: 2.3223e-04\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9791e-04 - val_loss: 1.1140e-04\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9405e-04 - val_loss: 1.3959e-05\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7318e-04 - val_loss: 2.5406e-05\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7405e-04 - val_loss: 3.5675e-05\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7406e-04 - val_loss: 3.3599e-04\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.8727e-04 - val_loss: 3.3128e-05\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.6320e-04 - val_loss: 6.5338e-05\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9377e-04 - val_loss: 3.4331e-04\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8693e-04 - val_loss: 3.0713e-05\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7931e-04 - val_loss: 1.3741e-04\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.5547e-04 - val_loss: 1.9618e-04\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.5796e-04 - val_loss: 6.9249e-05\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7217e-04 - val_loss: 2.1021e-05\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7829e-04 - val_loss: 3.6650e-05\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6859e-04 - val_loss: 2.1095e-05\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.4892e-04 - val_loss: 1.9657e-04\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6405e-04 - val_loss: 1.5660e-05\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9276e-04 - val_loss: 1.0215e-04\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6409e-04 - val_loss: 2.9757e-05\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7897e-04 - val_loss: 3.3697e-05\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0218e-04 - val_loss: 3.5551e-05\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.1879e-04 - val_loss: 1.7375e-04\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9754e-04 - val_loss: 2.2824e-05\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6715e-04 - val_loss: 2.2181e-04\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8936e-04 - val_loss: 4.9536e-05\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9190e-04 - val_loss: 2.5088e-05\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0095e-04 - val_loss: 4.5114e-05\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9069e-04 - val_loss: 2.4529e-05\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.5816e-04 - val_loss: 1.9333e-04\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8093e-04 - val_loss: 3.4093e-05\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0148e-04 - val_loss: 5.0742e-05\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9140e-04 - val_loss: 4.8123e-05\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6868e-04 - val_loss: 1.8973e-05\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7258e-04 - val_loss: 7.9359e-05\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6553e-04 - val_loss: 3.6099e-05\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7985e-04 - val_loss: 2.7648e-04\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.5175e-04 - val_loss: 4.5564e-05\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7223e-04 - val_loss: 8.6006e-05\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8422e-04 - val_loss: 4.3008e-05\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8513e-04 - val_loss: 2.4737e-05\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9111e-04 - val_loss: 8.3639e-05\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7322e-04 - val_loss: 5.6300e-05\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9452e-04 - val_loss: 1.0038e-04\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.1899e-04 - val_loss: 8.7216e-05\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7101e-04 - val_loss: 2.6269e-05\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.5185e-04 - val_loss: 5.8157e-05\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6464e-04 - val_loss: 5.9789e-05\n",
      "TRAIN: [17048 17049 17050 ... 23864 23865 23866] TEST: [23867 23868 23869 ... 25569 25570 25571]\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 0.0010 - val_loss: 2.2233e-05\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.5809e-04 - val_loss: 5.4118e-06\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.4277e-04 - val_loss: 1.0345e-05\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5665e-04 - val_loss: 4.8885e-06\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4481e-04 - val_loss: 1.0332e-05\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8539e-04 - val_loss: 8.7709e-06\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9948e-04 - val_loss: 5.7501e-06\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7468e-04 - val_loss: 4.2051e-06\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7570e-04 - val_loss: 7.9592e-06\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6549e-04 - val_loss: 1.0748e-05\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9063e-04 - val_loss: 5.3255e-06\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8164e-04 - val_loss: 1.3060e-05\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9810e-04 - val_loss: 3.5495e-06\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.8654e-04 - val_loss: 2.3110e-05\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.8958e-04 - val_loss: 1.4909e-05\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9742e-04 - val_loss: 2.9052e-05\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.0410e-04 - val_loss: 1.4636e-05\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.1009e-04 - val_loss: 8.3311e-06\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.6148e-04 - val_loss: 2.8181e-06\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7814e-04 - val_loss: 7.9794e-05\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7280e-04 - val_loss: 8.3844e-06\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9272e-04 - val_loss: 1.2520e-05\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0838e-04 - val_loss: 6.4186e-06\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9053e-04 - val_loss: 3.6485e-06\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7334e-04 - val_loss: 4.9108e-05\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9097e-04 - val_loss: 1.0439e-04\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8079e-04 - val_loss: 1.2274e-05\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0077e-04 - val_loss: 1.4212e-05\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9165e-04 - val_loss: 2.0572e-05\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8592e-04 - val_loss: 6.3427e-05\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0191e-04 - val_loss: 1.0471e-05\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8994e-04 - val_loss: 2.4670e-05\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.8660e-04 - val_loss: 1.7660e-05\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.1349e-04 - val_loss: 1.7366e-05\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 2.7434e-04 - val_loss: 2.8345e-05\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8458e-04 - val_loss: 7.0874e-05\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 3.0913e-04 - val_loss: 9.7115e-06\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.0311e-04 - val_loss: 1.3879e-05\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7803e-04 - val_loss: 3.2499e-06\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7437e-04 - val_loss: 3.5003e-06\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0316e-04 - val_loss: 3.4959e-06\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8775e-04 - val_loss: 2.8238e-05\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9814e-04 - val_loss: 4.4200e-06\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0239e-04 - val_loss: 1.3808e-05\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8771e-04 - val_loss: 1.7594e-05\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8714e-04 - val_loss: 4.8708e-05\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7220e-04 - val_loss: 2.5397e-05\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7583e-04 - val_loss: 2.0607e-05\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.7472e-04 - val_loss: 9.6961e-05\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8520e-04 - val_loss: 3.7906e-06\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9353e-04 - val_loss: 3.1099e-05\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3547e-04 - val_loss: 4.0426e-06\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9261e-04 - val_loss: 1.8669e-05\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.6569e-04 - val_loss: 1.0979e-05\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7396e-04 - val_loss: 1.1888e-05\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7529e-04 - val_loss: 7.8522e-05\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9500e-04 - val_loss: 5.3822e-05\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2407e-04 - val_loss: 9.4884e-06\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8707e-04 - val_loss: 1.2209e-05\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8037e-04 - val_loss: 5.4531e-06\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 2.8980e-04 - val_loss: 4.9764e-06\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8001e-04 - val_loss: 7.8839e-06\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8774e-04 - val_loss: 1.8368e-05\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7299e-04 - val_loss: 2.4279e-05\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.5983e-04 - val_loss: 9.2451e-06\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8038e-04 - val_loss: 4.1537e-05\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9897e-04 - val_loss: 3.7080e-05\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9150e-04 - val_loss: 7.4658e-05\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.1108e-04 - val_loss: 2.9955e-05\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.0480e-04 - val_loss: 2.0388e-05\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7705e-04 - val_loss: 2.2177e-05\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9920e-04 - val_loss: 3.3886e-06\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9350e-04 - val_loss: 3.9905e-05\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.9589e-04 - val_loss: 6.1898e-06\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9454e-04 - val_loss: 3.7402e-06\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8156e-04 - val_loss: 3.9865e-05\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9924e-04 - val_loss: 5.2667e-05\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.1641e-04 - val_loss: 2.9065e-05\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7280e-04 - val_loss: 5.2891e-06\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9178e-04 - val_loss: 2.6929e-05\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9335e-04 - val_loss: 1.0068e-04\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8576e-04 - val_loss: 9.1573e-05\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4207e-04 - val_loss: 6.8447e-05\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9202e-04 - val_loss: 2.6247e-05\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8300e-04 - val_loss: 8.4237e-06\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 2.8347e-04 - val_loss: 2.0945e-05\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7296e-04 - val_loss: 2.7996e-05\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7992e-04 - val_loss: 9.5779e-05\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8201e-04 - val_loss: 4.0523e-05\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7946e-04 - val_loss: 2.7839e-05\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9500e-04 - val_loss: 7.8991e-06\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8690e-04 - val_loss: 8.1739e-05\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7863e-04 - val_loss: 1.4613e-05\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.0483e-04 - val_loss: 3.3319e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8835e-04 - val_loss: 2.9133e-05\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7586e-04 - val_loss: 1.5238e-05\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8765e-04 - val_loss: 3.8326e-05\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.8128e-04 - val_loss: 8.2908e-06\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.7683e-04 - val_loss: 7.7697e-06\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 2.9971e-04 - val_loss: 4.8138e-06\n",
      "TRAIN: [25572 25573 25574 ... 32388 32389 32390] TEST: [32391 32392 32393 ... 34093 34094 34095]\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9552e-04 - val_loss: 1.6046e-04\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7972e-04 - val_loss: 1.7468e-04\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.7934e-04 - val_loss: 1.7811e-04\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5207e-04 - val_loss: 1.9234e-04\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2589e-04 - val_loss: 1.7463e-04\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6024e-04 - val_loss: 2.8498e-04\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5708e-04 - val_loss: 2.0785e-04\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4974e-04 - val_loss: 1.7876e-04\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5568e-04 - val_loss: 2.0983e-04\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5380e-04 - val_loss: 1.7760e-04\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4338e-04 - val_loss: 1.8209e-04\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3884e-04 - val_loss: 2.6722e-04\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5046e-04 - val_loss: 5.9989e-04\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5086e-04 - val_loss: 1.8374e-04\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5280e-04 - val_loss: 2.5053e-04\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3559e-04 - val_loss: 1.7155e-04\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6022e-04 - val_loss: 4.1466e-04\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5551e-04 - val_loss: 1.7191e-04\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6377e-04 - val_loss: 1.7073e-04\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3778e-04 - val_loss: 2.0136e-04\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4492e-04 - val_loss: 1.9169e-04\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6927e-04 - val_loss: 2.1428e-04\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4756e-04 - val_loss: 1.7478e-04\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4893e-04 - val_loss: 1.9177e-04\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6020e-04 - val_loss: 2.1802e-04\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6348e-04 - val_loss: 1.7764e-04\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5403e-04 - val_loss: 3.0783e-04\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.4398e-04 - val_loss: 1.7184e-04\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6129e-04 - val_loss: 1.8046e-04\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.2740e-04 - val_loss: 1.6956e-04\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.5907e-04 - val_loss: 1.8412e-04\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.5058e-04 - val_loss: 1.7446e-04\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.2567e-04 - val_loss: 2.0871e-04\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.4142e-04 - val_loss: 1.7763e-04\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.3611e-04 - val_loss: 1.7119e-04\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6520e-04 - val_loss: 1.8319e-04\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4055e-04 - val_loss: 2.5571e-04\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3716e-04 - val_loss: 1.6501e-04\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2946e-04 - val_loss: 1.9059e-04\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.8019e-04 - val_loss: 3.4714e-04\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6625e-04 - val_loss: 2.1641e-04\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.5884e-04 - val_loss: 1.7825e-04\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 3.2851e-04 - val_loss: 1.9858e-04\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 3.5188e-04 - val_loss: 1.8367e-04\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3325e-04 - val_loss: 1.6634e-04\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3937e-04 - val_loss: 3.4398e-04\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.6622e-04 - val_loss: 2.3821e-04\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 3s 24ms/step - loss: 3.3569e-04 - val_loss: 2.1148e-04\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 3.3049e-04 - val_loss: 1.8024e-04\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6241e-04 - val_loss: 1.8784e-04\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4410e-04 - val_loss: 1.8246e-04\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4065e-04 - val_loss: 1.7394e-04\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5256e-04 - val_loss: 2.7156e-04\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.6338e-04 - val_loss: 1.7385e-04\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4488e-04 - val_loss: 2.1737e-04\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5657e-04 - val_loss: 1.8433e-04\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2578e-04 - val_loss: 1.8135e-04\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4958e-04 - val_loss: 3.2594e-04\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5105e-04 - val_loss: 2.2810e-04\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4846e-04 - val_loss: 1.8337e-04\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.6168e-04 - val_loss: 1.8815e-04\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.6069e-04 - val_loss: 2.0657e-04\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4759e-04 - val_loss: 1.7822e-04\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5347e-04 - val_loss: 2.0902e-04\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5548e-04 - val_loss: 1.9447e-04\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.1170e-04 - val_loss: 1.7285e-04\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3594e-04 - val_loss: 1.8786e-04\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5052e-04 - val_loss: 3.3636e-04\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4745e-04 - val_loss: 1.8556e-04\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3761e-04 - val_loss: 2.4065e-04\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2049e-04 - val_loss: 1.7903e-04\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3832e-04 - val_loss: 1.8148e-04\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2797e-04 - val_loss: 1.7601e-04\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.5401e-04 - val_loss: 1.9523e-04\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2953e-04 - val_loss: 1.8253e-04\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5390e-04 - val_loss: 1.9380e-04\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.2515e-04 - val_loss: 1.7999e-04\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3894e-04 - val_loss: 1.8637e-04\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 3.3938e-04 - val_loss: 2.0831e-04\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5347e-04 - val_loss: 1.8538e-04\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 3s 23ms/step - loss: 3.3253e-04 - val_loss: 1.8161e-04\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4603e-04 - val_loss: 1.7614e-04\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2571e-04 - val_loss: 1.8807e-04\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4060e-04 - val_loss: 1.8707e-04\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5125e-04 - val_loss: 2.1176e-04\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5695e-04 - val_loss: 1.8608e-04\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4301e-04 - val_loss: 1.8651e-04\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2279e-04 - val_loss: 1.8469e-04\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2069e-04 - val_loss: 1.8121e-04\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5785e-04 - val_loss: 1.8611e-04\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4418e-04 - val_loss: 2.0732e-04\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3874e-04 - val_loss: 2.4671e-04\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.2945e-04 - val_loss: 1.7875e-04\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.4624e-04 - val_loss: 1.9675e-04\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.4129e-04 - val_loss: 1.8542e-04\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.5962e-04 - val_loss: 1.8502e-04\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.5756e-04 - val_loss: 4.2823e-04\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.5207e-04 - val_loss: 3.0762e-04\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 3.3997e-04 - val_loss: 3.1118e-04\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 3.3218e-04 - val_loss: 2.0687e-04\n",
      "TRAIN: [34096 34097 34098 ... 40912 40913 40914] TEST: [40915 40916 40917 ... 42617 42618 42619]\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 0.0021 - val_loss: 7.7836e-06\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 0.0011 - val_loss: 6.0215e-05\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 7.9728e-04 - val_loss: 8.4615e-05\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 6.7544e-04 - val_loss: 3.0551e-05\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 6.5264e-04 - val_loss: 1.8541e-05\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.4884e-04 - val_loss: 4.8944e-06\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0779e-04 - val_loss: 6.5736e-06\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3143e-04 - val_loss: 1.2473e-05\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1416e-04 - val_loss: 1.0338e-05\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2439e-04 - val_loss: 5.9848e-05\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9156e-04 - val_loss: 6.3781e-05\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0723e-04 - val_loss: 1.4908e-05\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1449e-04 - val_loss: 8.8124e-06\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1724e-04 - val_loss: 8.7796e-06\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.7721e-04 - val_loss: 1.1715e-05\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.9531e-04 - val_loss: 1.0702e-04\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2007e-04 - val_loss: 1.5882e-05\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1246e-04 - val_loss: 7.9802e-06\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1888e-04 - val_loss: 1.5942e-05\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0264e-04 - val_loss: 1.5180e-05\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.8374e-04 - val_loss: 2.6813e-05\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1187e-04 - val_loss: 9.7320e-06\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9441e-04 - val_loss: 1.6731e-04\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1432e-04 - val_loss: 4.3356e-05\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0282e-04 - val_loss: 4.4247e-05\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2612e-04 - val_loss: 8.1718e-05\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0644e-04 - val_loss: 2.0107e-05\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0811e-04 - val_loss: 1.3233e-05\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9618e-04 - val_loss: 2.4780e-05\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1041e-04 - val_loss: 2.8885e-06\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.3661e-04 - val_loss: 5.6927e-05\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.4832e-04 - val_loss: 1.9484e-05\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9486e-04 - val_loss: 1.7436e-05\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1348e-04 - val_loss: 1.4714e-05\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1581e-04 - val_loss: 6.2426e-05\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.2165e-04 - val_loss: 5.3521e-05\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.0904e-04 - val_loss: 2.3284e-04\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9914e-04 - val_loss: 5.2798e-05\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1234e-04 - val_loss: 1.3439e-05\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9724e-04 - val_loss: 3.1905e-05\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0867e-04 - val_loss: 9.8227e-06\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9240e-04 - val_loss: 3.1508e-05\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0674e-04 - val_loss: 1.4340e-04\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.0900e-04 - val_loss: 6.1511e-05\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0217e-04 - val_loss: 7.2734e-05\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9162e-04 - val_loss: 3.7358e-05\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3701e-04 - val_loss: 1.3026e-04\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2183e-04 - val_loss: 3.1141e-05\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2329e-04 - val_loss: 9.2842e-06\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1929e-04 - val_loss: 2.5727e-05\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1413e-04 - val_loss: 2.3580e-05\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.3904e-04 - val_loss: 2.6970e-05\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.3420e-04 - val_loss: 4.8992e-06\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.3024e-04 - val_loss: 9.8093e-06\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.0030e-04 - val_loss: 1.9825e-05\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.2803e-04 - val_loss: 5.0367e-05\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1753e-04 - val_loss: 8.0133e-05\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.3108e-04 - val_loss: 1.1425e-05\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.0427e-04 - val_loss: 2.6542e-05\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0778e-04 - val_loss: 3.1783e-05\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1619e-04 - val_loss: 1.3159e-04\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3497e-04 - val_loss: 1.9045e-05\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3971e-04 - val_loss: 2.8283e-05\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9610e-04 - val_loss: 2.1420e-05\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0054e-04 - val_loss: 1.9797e-05\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0543e-04 - val_loss: 6.0432e-06\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 5.1817e-04 - val_loss: 2.0437e-05\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.1186e-04 - val_loss: 6.6999e-05\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1504e-04 - val_loss: 2.0652e-05\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.2361e-04 - val_loss: 4.7738e-05\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 5.1230e-04 - val_loss: 1.3202e-05\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1636e-04 - val_loss: 1.0697e-05\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.9291e-04 - val_loss: 2.5495e-05\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.0089e-04 - val_loss: 2.9139e-05\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 4.9228e-04 - val_loss: 7.4491e-06\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.7548e-04 - val_loss: 1.7537e-05\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 3s 27ms/step - loss: 4.9224e-04 - val_loss: 9.6422e-06\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3546e-04 - val_loss: 4.2517e-05\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 2s 23ms/step - loss: 5.1210e-04 - val_loss: 1.5275e-05\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.3795e-04 - val_loss: 1.4833e-04\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.8860e-04 - val_loss: 4.2289e-06\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9336e-04 - val_loss: 6.1535e-06\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9131e-04 - val_loss: 5.5306e-05\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3428e-04 - val_loss: 1.7400e-05\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0291e-04 - val_loss: 9.6873e-06\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3857e-04 - val_loss: 3.3664e-05\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9326e-04 - val_loss: 1.4005e-05\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0002e-04 - val_loss: 4.1721e-05\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.2427e-04 - val_loss: 6.6518e-05\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3709e-04 - val_loss: 1.6480e-05\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 4.9836e-04 - val_loss: 2.3285e-04\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3025e-04 - val_loss: 2.2243e-04\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.3867e-04 - val_loss: 9.0818e-06\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.2187e-04 - val_loss: 6.7721e-05\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.1936e-04 - val_loss: 5.9590e-05\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 3s 26ms/step - loss: 5.0614e-04 - val_loss: 7.9568e-06\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.1590e-04 - val_loss: 3.6710e-05\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.2656e-04 - val_loss: 4.4147e-05\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.0111e-04 - val_loss: 1.7366e-05\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 3s 25ms/step - loss: 5.2384e-04 - val_loss: 4.6229e-05\n"
     ]
    }
   ],
   "source": [
    "fold_num = 1\n",
    "for train_index, test_index in btscv.split(xtrain):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = xtrain[train_index], xtrain[test_index]\n",
    "    y_train, y_test = ytrain[train_index], ytrain[test_index]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data = (X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=64\n",
    "        #callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    loss_df['Loss ' + str(fold_num)] = history.history['loss']\n",
    "    val_loss_df['Val_loss ' + str(fold_num)] = history.history['val_loss']\n",
    "    \n",
    "    fold_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = [32, 64]\n",
    "epochs = [80,100,120]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=1, cv=btscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid_result = grid.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    model.fit(\n",
    "        xtrain,\n",
    "        ytrain,\n",
    "        validation_split=0.2,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss 1</th>\n",
       "      <th>Loss 2</th>\n",
       "      <th>Loss 3</th>\n",
       "      <th>Loss 4</th>\n",
       "      <th>Loss 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029246</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008644</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loss 1    Loss 2    Loss 3    Loss 4    Loss 5\n",
       "0   0.029246  0.000684  0.001001  0.000496  0.002090\n",
       "1   0.008644  0.000576  0.000558  0.000380  0.001149\n",
       "2   0.006188  0.000365  0.000443  0.000379  0.000797\n",
       "3   0.005004  0.000296  0.000357  0.000352  0.000675\n",
       "4   0.004496  0.000302  0.000345  0.000326  0.000653\n",
       "..       ...       ...       ...       ...       ...\n",
       "95  0.000336  0.000295  0.000276  0.000360  0.000506\n",
       "96  0.000332  0.000319  0.000288  0.000358  0.000516\n",
       "97  0.000327  0.000271  0.000281  0.000352  0.000527\n",
       "98  0.000332  0.000252  0.000277  0.000340  0.000501\n",
       "99  0.000345  0.000265  0.000300  0.000332  0.000524\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Val_loss 1</th>\n",
       "      <th>Val_loss 2</th>\n",
       "      <th>Val_loss 3</th>\n",
       "      <th>Val_loss 4</th>\n",
       "      <th>Val_loss 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Val_loss 1  Val_loss 2  Val_loss 3  Val_loss 4  Val_loss 5\n",
       "0     0.002525    0.000037    0.000022    0.000160    0.000008\n",
       "1     0.001056    0.000166    0.000005    0.000175    0.000060\n",
       "2     0.000291    0.000187    0.000010    0.000178    0.000085\n",
       "3     0.000424    0.000057    0.000005    0.000192    0.000031\n",
       "4     0.000585    0.000055    0.000010    0.000175    0.000019\n",
       "..         ...         ...         ...         ...         ...\n",
       "95    0.000016    0.000100    0.000015    0.000185    0.000008\n",
       "96    0.000030    0.000087    0.000038    0.000428    0.000037\n",
       "97    0.000011    0.000026    0.000008    0.000308    0.000044\n",
       "98    0.000015    0.000058    0.000008    0.000311    0.000017\n",
       "99    0.000024    0.000060    0.000005    0.000207    0.000046\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(palette=\"ch:s=.25,rot=-.25\")\n",
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(data=loss_df, x=loss_df.index, y=\"Loss 5\", ax = ax, color=\"b\", label='Training Loss')\n",
    "sns.lineplot(data=val_loss_df, x=val_loss_df.index, y=\"Val_loss 5\", ax = ax, color=\"r\", label='Validation Loss')\n",
    "ax.set_xlabel(\"Épocas\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.savefig(\"test_CV_mala.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../Models/test_CV_mala.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
